# Conditional Facies Modeling Using an Improved Progressive Growing of Generative Adversarial Networks (GANs) 

*** Since Github does not allow large files to be downloaded, such as "Trainingdata" and "TrainingResults", thus we also upload all the data (codes, training data and training results) into Zenodo https://zenodo.org/record/3993791#.Xz8My8hKhaQ.

This work is different from those "post-GAN" facies modeling approaches, in which an unconditional GAN is first trained and then "post-GAN" optimization algorithms are performed to achieve conditioning to observed geological data. One major problems for "post-GAN" approaches is that, once the observed conditioning data changes, the time-consuming optimization algorithm needs to be performed again. Instead, we propose a direct conditional facies modeling approach based on progressive growing of GANs. In our approach, the GAN conditioned to various observed data can be directly trained, and after training, the generator can directly map any conditioning observed data into various facies models that are consistent with the input conditioning observed data. Our full paper (Conditional Facies Modeling Using an Improved Progressive Growing of Generative Adversarial Networks (GANs) by Suihong Song, Tapan Mukerji, and Jiagen Hou) is public on EarhArvix and Researchgate: https://www.researchgate.net/publication/342539722_Conditional_Facies_Modeling_Using_an_Improved_Progressive_Growing_of_Generative_Adversarial_Networks_GANs (linke on Researchgate).

This repository includes 3 big folders: "Trainingdata" (in the form of .7z), "Code", and "TrainingResults" (in the form of .7z). Code for this project is improved from the original code of Progressive growing of GANs (https://github.com/tkarras/progressive_growing_of_gans). We thank the authors for their great job. 

"Code" folder includes two subfolders: "0_Code for only conditioning to global features" and "1_Code for conditioning to well facies alone or with global features".  (1) Codes in the first subfolder are only for the case of only conditioning to global features, where the inputs of the generator include random latent vector and global feature values: [[None, 128], [None, 3]]. (2) The codes in the second subfolder are for cases of conditioning to only well facies data, and jointly conditioning to both well facies data and global features. The inputs of the generator include random latent vector, global features, and well facies data. In the case of only conditioning to well facies data, the dimension for input global features is 0, i.e., the input of generator is [[None, 128], [None, 0], [None, 2, 64, 64]]. In the case of jointly conditioning to both well facies data and global features, the dimension for input global features is 1 for 1 global feature, i.e., the input of generator is [[None, 128], [None, 1], [None, 2, 64, 64]].  

Before training, set hyperparameters in "config.py" file: path for download "Trainingdata" where "TraningData" and "TestData" folders are included (not path for "TrainingData"), path for result directary, gpu numbers, conditioning global features (if no global feature needs to be conditioned, leave labeltypes = []), etc. See comment of "config.py" for details of each settings. 
Then, run "train.py" or run code in “Run Code.ipynb” file (adjust the path to code at first line). 

Most of the evaluation workflow and codes are included in the two subfolders of "Code" folder, with the name format of "Analyses_of_Trained_Generator-xxxx.ipynb". 
